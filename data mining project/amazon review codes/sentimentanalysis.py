# -*- coding: utf-8 -*-
"""sentimentanalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bp6BSfQ-LsxbFGObYNrSIfoNDnJqTdE-
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import matplotlib.pyplot as plt
plt.style.use('ggplot')
import numpy as np
import seaborn as sns

import nltk

"""
**Read the dataset first rows of the  dataset**"""

df = pd.read_csv('/content/drive/MyDrive/Amazonproductreviews/archive (19)/Reviews.csv')
df.head()

df.shape

df.columns

df.info()

"""dropping null values"""

#Limit the size of the dataset for faster processing to a number of your choice, I chose 500.
df.head(500)

# Generate a bar plot showing the distribution of review scores,
ax= df['Score'].value_counts().sort_index() \
.plot(kind='bar', title ='conunt of reviews by stars',
figsize =(10,5))
ax.set_xlabel('star rating')
ax.set_ylabel('count')
plt.show

"""**Sentiment Analysis**

**Download necessary NLTK resources such as lexicons, tokenizers, and part-of-speech taggers.**
"""

nltk.download('vader_lexicon')
nltk.download('words')
nltk.download('maxent_ne_chunker')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

"""**extracting one review from the 500**"""

examplereview=df['Text'][49]
print(examplereview)

# Tokenize the content and slice it for faster processing

tokens=nltk.word_tokenize(examplereview)
tokens[:10]

"""**Part-of-speech (POS) tagging, to assign a part-of-speech tag to each tokenized word in the review.**"""

tagged=nltk.pos_tag(tokens)
tagged[:10]

entities=nltk.chunk.ne_chunk(tagged)
entities.pprint()

""" **First Model:VADER**"""

from nltk.sentiment import SentimentIntensityAnalyzer
sia=SentimentIntensityAnalyzer()

"""** Apply VADER Sentiment Analysis on the dataset**"""

!pip install tqdm

from tqdm import tqdm

#run the polarity  score on the entire dataset
res = {}
for i,row in tqdm(df.iterrows(), total=len(df)):
   text=row['Text']
   myid=row['Id']
   res[myid]= sia.polarity_scores(text)

#Plot VADER results
vaders= pd.DataFrame(res).T
vaders= vaders.reset_index().rename(columns={'index':'Id'})
vaders= vaders.merge(df, how='left')
# Check the resulting DataFrame
vaders.head()

"""**Visualize VADER results**"""

#Plot a bar graph to visualize the results
ax=  sns.barplot(data=vaders, x='Score', y='compound')
ax.set_title('compound scores for amazon reviews')
plt.show()

"""**This indicates that most of the reviews are positive and with a high sentiment polarity in positivity while the negative reviews are few and have low sentiment polarity**"""

df.columns

#subplots for each category
import seaborn as sns

fig, axs = plt.subplots(1, 3, figsize=(15, 3))
sns.barplot(data=vaders, x='Score', y='pos', ax=axs[0])
sns.barplot(data=vaders, x='Score', y='neu', ax=axs[1])
sns.barplot(data=vaders, x='Score', y='neg', ax=axs[2])

axs[0].set_title('Positive')
axs[0].set_title('rating')
axs[0].set_title('polarity')

axs[1].set_title('neutral')
axs[1].set_title('rating')
axs[1].set_title('polarity')

axs[2].set_title('negative')
axs[2].set_title('rating')
axs[2].set_title('polarity')

plt.show()

"""**Conclusion**
Summary of Findings:
•	VADER shows higher, with a high number of positive reviews and very few negative reviews.
•	The sentiment analysis revealed that most of the reviews in the dataset were positive, indicating overall satisfaction with the products.





"""